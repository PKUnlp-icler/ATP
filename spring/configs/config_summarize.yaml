name: 1017_Summary_dialoguesumm_seed456
model: facebook/bart-large

# <--------------
# Linearizations
# Comment DFS and uncomment the relevant block if you want to use a different linearization scheme

# DFS
penman_linearization: True
use_pointer_tokens: True
raw_graph: False

# BFS
# penman_linearization: False
# use_pointer_tokens: True
# raw_graph: False

# PENMAN
# penman_linearization: True
# use_pointer_tokens: False
# raw_graph: False

# BART baseline
# penman_linearization: True
# use_pointer_tokens: False
# raw_graph: True

remove_wiki: False
dereify: False
collapse_name_ops: False

# Hparams
batch_size: 1024
beam_size: 1
dropout: 0.25
attention_dropout: 0.0
smart_init: True
accum_steps: 20
warmup_steps: 1
training_steps: 10000000
weight_decay: 0.004
grad_norm: 2.5
scheduler: constant
learning_rate: 0.00005
max_epochs: 30
save_checkpoints: True
log_wandb: False
warm_start: True
use_recategorization: False
best_loss: False
remove_longer_than: 1024
seed: 456
train_mode: None
reserve_p : 0.3


# <------------------
# AMR Data: replace DATA below with the root of your AMR 2/3 release folder
# train: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/dev/*.txt
# dev: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/dev/*.txt
# test: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/test/*.txt


# <------------------
# Pretrain Data: replace DATA below with the root of your AMR 2/3 release folder
#200k
# train_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/wmt14_en/train.en.200k.silver.src
# train_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/wmt14_en/train.en.200k.lemmatized.rr


#40k_rr
# train_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/train.seq.src
# train_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/train.seq.gold.lemmatized.rr


# dev_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/dev.seq.src
# dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/dev.seq.gold.lemmatized.rr

# test_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/test.seq.src
# test_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/test.seq.gold.lemmatized.rr


#40k srl trival
# train_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_src.txt.train
# train_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_trival_linerization.gold.txt.train


# dev_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_src.txt.dev
# dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_trival_linerization.gold.txt.dev

# test_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_src.txt.dev
# test_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_trival_linerization.gold.txt.dev

#40k summary dialogue
train_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/train.src
train_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/train.tgt

dev_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/dev.src
dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/dev.tgt

test_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/dev.src
test_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/DialogSumm/dev.tgt

# train_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.train.src
# train_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.train.tgt

# dev_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.dev.src
# dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.dev.tgt

# test_src: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.dev.src
# test_gold: /home/cl/AMR_Multitask_Inter/Dataset/Summarzation/CNNDM/cnndm.dev.tgt


