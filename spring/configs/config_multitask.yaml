name: 1022_2.0_keepup_amr_multitask_123_beam5
model: facebook/bart-large

# <--------------
# Linearizations
# Comment DFS and uncomment the relevant block if you want to use a different linearization scheme

# DFS
penman_linearization: True
use_pointer_tokens: True
raw_graph: False

# BFS
# penman_linearization: False
# use_pointer_tokens: True
# raw_graph: False

# PENMAN
# penman_linearization: True
# use_pointer_tokens: False
# raw_graph: False

# BART baseline
# penman_linearization: True
# use_pointer_tokens: False
# raw_graph: True

remove_wiki: False
dereify: False
collapse_name_ops: False

# Hparams
batch_size: 2048
beam_size: 5
dropout: 0.25
#0.3
attention_dropout: 0
#0
smart_init: True
accum_steps: 10
warmup_steps: 1
training_steps: 800000
weight_decay: 0.004
grad_norm: 2.5
scheduler: constant
learning_rate: 0.00005
#0.00005 source
max_epochs: 50
save_checkpoints: True
log_wandb: False
warm_start: True
use_recategorization: False
best_loss: False
remove_longer_than: 1024
seed: 123
train_mode: ChildTuning-F
reserve_p : 0.3


# <------------------
# AMR Data: replace DATA below with the root of your AMR 2/3 release folder
amr_train: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/training/*.txt
amr_dev: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/dev/*.txt
amr_test: /home/cl/AMR_Active/AMR_Dataset/abstract_meaning_representation_amr_2.0/data/amrs/split/test/*.txt

#40k srl arg_reduction + reen
srl_train_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_arg_reduction_reen.txt.src.train
srl_train_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_linerization_arg_reduction_reen.txt.gold.train

srl_dev_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_arg_reduction_reen.txt.src.dev
srl_dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_linerization_arg_reduction_reen.txt.gold.dev

srl_test_src: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_arg_reduction_reen.txt.src.dev
srl_test_gold: /home/cl/AMR_Multitask_Inter/Dataset/SRL/Ontonotes/ontonotes_english/srl_linerization_arg_reduction_reen.txt.gold.dev

#40k_rr no det punct
dp_train_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/train.seq.src
dp_train_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/conll15_no_pointer_without_det_punct/train.seq.lemmatized.rr


dp_dev_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/dev.seq.src
dp_dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/conll15_no_pointer_without_det_punct/dev.seq.lemmatized.rr

dp_test_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq(lemma)/dev.seq.src
dp_test_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/conll15_no_pointer_without_det_punct/dev.seq.lemmatized.rr
# AMR 3.0

# train: /home/cl/AMR_Multitask_Inter/Dataset/DP/amr_annotation_3.0/data/amrs/split/training/*.txt
# dev: /home/cl/AMR_Multitask_Inter/Dataset/DP/amr_annotation_3.0/data/amrs/split/dev/*.txt
# test: /home/cl/AMR_Multitask_Inter/Dataset/DP/amr_annotation_3.0/data/amrs/split/test/*.txt


# <------------------
# Pretrain Data: replace DATA below with the root of your AMR 2/3 release folder
# train_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/dev.seq.src
# train_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/dev.seq.gold

# dev_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/dev.seq.src
# dev_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/dev.seq.gold

# test_src: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/test.seq.src
# test_gold: /home/cl/AMR_Multitask_Inter/Dataset/DP/seq2seq/test.seq.src